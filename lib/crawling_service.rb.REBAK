# lib/crawling_service.rb
# frozen_string_literal: true

require 'mechanize'
require 'nokogiri'
require 'byebug'

class CrawlingService
  attr_reader :results

  def initialize(attributes = {})
    @search_topic = attributes[:search_topic] || '処理水'
    @from = attributes[:from] || 1
    @to = attributes[:to] || 2
    @total_pages = 3
    @results = []
  end

  def crawl
    agent = Mechanize.new
    agent.user_agent_alias = 'Windows Chrome'

    page = agent.get('http://j.people.com.cn/')
    puts "Page title: #{page.title}"
    form = page.form_with(name: 'searchForm1')
    form.field_with(name: 'keyword').value = @search_topic

    result_page = form.submit
    index = 1

    while index <= @total_pages
      puts "Currently reading page #{index}/#{@total_pages} (#{format('%.2f', 100 * index / @total_pages.to_f)}%)"

      # Wait for search results to load by checking for the presence of a result element
      wait_for_results(agent)

      parse_results(result_page)

      break unless next_page_link(result_page)

      result_page = next_page_link(result_page).click
      index += 1
    end

    @results
  end

  private

  def wait_for_results(agent, max_attempts = 30)
    attempts = 0

    while attempts < max_attempts
      break if result_elements_present?(agent)
      sleep(1) # Sleep for 1 second before checking again
      attempts += 1
    end
  end

  def result_elements_present?(agent)
    page = agent.page
    doc = Nokogiri::HTML(page.body)
    doc.css('.your-result-selector').any?
  end

  def parse_results(page)
    doc = Nokogiri::HTML(page.body)
    byebug
    doc.css('dt').each do |element|
      url = element.at_xpath('.//a')['href']
      title = element.at_xpath('.//a').text
      @results << { title: title, url: url }
    end
  end

  def next_page_link(page)
    page.link_with(text: '次ページ')
  end
end
